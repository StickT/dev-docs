<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.5.0_06) on Mon Jun 26 19:39:32 EDT 2006 -->
<TITLE>
Overview (Scheduling)
</TITLE>

<META NAME="keywords" CONTENT="Overview">

<LINK REL ="stylesheet" TYPE="text/css" HREF="stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    parent.document.title="Overview (Scheduling)";
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">

<HR>
Scheduling
                This section describes classes that control scheduling.
<P>
<B>See:</B>
<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<A HREF="#overview_description"><B>Description</B></A>
<P>

<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Packages</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD WIDTH="20%"><B><A HREF="javax/realtime/package-summary.html">javax.realtime</A></B></TD>
<TD>&nbsp;</TD>
</TR>
</TABLE>

<P>
&nbsp;<A NAME="overview_description"><!-- --></A>
<P>
<h1>Scheduling</h1>
                <p>This section describes classes that control scheduling. These classes:</p>
                <ul>
                        <li>Allow the definition of schedulable objects.
                        <li>Manage the assignment of execution eligibility to schedulable objects.
                        <li>Perform feasibility analysis for a set of schedulable objects.
                        <li>Control the admission of new schedulable objects to the feasibility set.
                        <li>Manage the execution of instances of the <code>AsyncEventHandler</code> and <code>RealtimeThread</code> classes.
                        <li>Assign release characteristics to schedulable objects.
                        <li>Assign execution eligibility values to schedulable objects.
                        <li>Manage the execution of groups of schedulable objects that collectively exhibit additional release characteristics.
                </ul>
                <h2>Definitions and Abbreviations</h2>
                <p>Schedulable objects include three execution states: <i>executing</i>, <i>blocked</i>, and <i>eligible-for-execution</i>.</p>
                <ul>
                        <li><i>Executing</i> refers to the state where the SO is currently running on a processor.
                        <li><i>Blocked</i> refers to the state where the SO is not among those SO's which could be selected to have their state changed to executing. The blocked state will have a reason associated with it, e.g., blocked-for-I/O-completion, blocked-for-release-event, or blocked-by-cost-overrun.
                        <li><i>Eligible-for-execution</i> refers to the state where the SO could be selected to have its state changed to executing.
                </ul>
                <p>Each type of schedulable object defines its own <i>release events</i>, for example, the release events for a periodic SO occur with the passage of time.</p>
                <p><i>Release</i> is the changing of the state of a schedulable object from blocked-for-release-event to eligible-for-execution. If the state of an SO is blocked-for-release-event when a release event occurs then the state of the SO is changed to eligible-for-execution. Otherwise, a state transition from blocked-for-release-event to eligible-for-execution is queued&mdash;this is known as a <em>pending release</em>. When the next transition of the SO into state blocked-for-release-event occurs, and there is a pending release, the state of the SO is immediately changed to eligible-for-execution. (Some actions implicitly clear any pending releases.)</p>
                <p><i>Completion</i> is the changing of the state of a schedulable object from executing to blocked-for-release-event. Each completion corresponds to a release. A real-time thread is deemed to complete its most recent release when it terminates.</p>
                <p><i>Deadline</i> refers to a time before which a schedulable object expects to complete. The i<sup>th</sup> deadline is associated with the i<sup>th</sup> release event and a <i>deadline miss</i> occurs if the i<sup>th</sup> completion would occur after the i<sup>th</sup> deadline.</p>
                <p><i>Deadline monitoring</i> is the process by which the implementation responds to deadline misses. If a deadline miss occurs for a schedulable object, the deadline miss handler, if any, for that SO is released. This behaves as if there were an asynchronous event associated with the SO, to which the miss handler was bound, and which was fired when the deadline miss occurred.</p>
                <p><i>Periodic</i>, <i>sporadic</i>, and <i>aperiodic</i> are adjectives applied to schedulable objects which describe the temporal relationship between consecutive release events. Let <em>R<sub>i</sub></em> denote the time at which an SO has had the<em> i<sup>th</sup></em> release event occur. Ignoring the effect of release jitter:</p>
                <ul>
                        <li>An SO is periodic when there exists a value <em>T&gt;0</em> such that for all <em>i, R<sub>i+1</sub> - R<sub>i</sub> = T,</em> where <em>T</em> is called the period.
                        <li>An SO that is not periodic is said to be aperiodic.
                        <li>An aperiodic SO is said to be sporadic when there is a known value <em>T&gt;0</em> such that for all <em>i, R<sub>i+1</sub> - R<sub>i</sub> &gt;= T. </em><em>T</em> is then called the minimum interarrival time (MIT).
                </ul>
                <p>The <i>cost</i> of a schedulable object is an estimate of the maximum amount of CPU time that the SO requires between a release and its associated completion.</p>
                <p>The <i>current CPU consumption</i> of a schedulable object is the amount of CPU time that the SO has consumed since its last release.</p>
                <p>A <i>cost overrun</i> occurs when the schedulable object's current CPU consumption becomes greater than, or equal to, its cost.</p>
                <p><i>Cost monitoring</i> is the process by which the implementation tracks CPU consumption and responds to cost overruns. If a cost overrun occurs for a schedulable object, the cost overrun handler, if any, for that SO is released. This behaves as if there were an asynchronous event associated with the SO, to which the overrun handler was bound, and which was fired when the cost overrun occurred. (Cost monitoring is an optional facility in an implementation of the RTSJ.)</p>
                <p>The <i>base priority</i> of a schedulable object is the priority given in its associated <a href="javax/realtime/PriorityParameters.html"><code>PriorityParameters</code></a> object; the base priority of a Java thread is the priority returned by its <code>getPriority</code> method.</p>
                <p>When it is not in the <a href="#Anchor-35326">enforced state</a>, the <i>active priority</i> of a schedulable object or a Java thread is the maximum of its base priority and any priority it has acquired due to the action of priority inversion avoidance algorithms (see the <a href="sync_overview-summary.html"><i>Synchronization Chapter),</i></a> </p>
                <p>A <i>processing group</i> is a collection of schedulable objects whose combined execution has further time constraints which the scheduler uses to govern the group's execution eligibility.</p>
                <p>A <i>scheduler</i> manages the execution of schedulable objects: it detects deadline misses, and performs admission control and cost monitoring. It also manages the execution of Java threads.</p>
                <p>The <i>base scheduler</i> is an instance of the <a href="javax/realtime/PriorityScheduler.html"><code>PriorityScheduler</code></a> class as defined in this specification. This is the initial default scheduler.</p>
                <h2>Overview</h2>
                <p>The scheduler required by this specification is fixed-priority preemptive with at least 28 unique priority levels. It is represented by the class <a href="javax/realtime/PriorityScheduler.html"><code>PriorityScheduler</code></a> and is called the <i>base scheduler.</i></p>
                <p>The schedulable objects required by this specification are defined by the classes <a href="javax/realtime/RealtimeThread.html"><code>RealtimeThread</code></a>, <a href="realtime/NoHeapRealtimeThread.html"><code>NoHeapRealtimeThread</code></a>, <a href="realtime/AsyncEventHandler.html"><code>AsyncEventHandler</code></a> and <a href="/realtime/BoundAsyncEventHandler.html"><code>BoundAsyncEventHandler</code></a>. The base scheduler assigns processor resources according to the schedulable objects' release characteristics, execution eligibility, and processing group values. Subclasses of the schedulable objects are also schedulable objects and behave as these required classes.</p>
                <p>An instance of the <a href="javax/realtime/SchedulingParameters.html"><code>SchedulingParameters</code></a> class contains values of execution eligibility. A schedulable object is considered to have the execution eligibility represented by the <a href="javax/realtime/SchedulingParameters.html"><code>SchedulingParameters</code></a> object currently bound to it. For implementations providing only the base scheduler, the scheduling parameters object is an instance of <a href="javax/realtime/PriorityParameters.html"><code>PriorityParameters</code></a> (a subclass of <a href="javax/realtime/SchedulingParameters.html"><code>SchedulingParameters</code></a>).</p>
                <p>An instance of the <a href="javax/realtime/ReleaseParameters.html"><code>ReleaseParameters</code></a> class or its subclasses, <a href="javax/realtime/PeriodicParameters.html"><code>PeriodicParameters</code></a>, <a href="javax/realtime/AperiodicParameters.html"><code>AperiodicParameters</code></a>, and <a href="javax/realtime/SporadicParameters.html"><code>SporadicParameters</code></a>, contains values that define a particular release characteristic. A schedulable object is considered to have the release characteristics of a single associated instance of the <a href="javax/realtime/ReleaseParameters.html"><code>ReleaseParameters</code></a> class. In all cases the base scheduler uses these values to perform its feasibility analysis over the set of schedulable objects and admission control for the schedulable object.</p>
                <p>For a real-time thread the scheduler defines the behavior of the real-time thread's <a href="javax/realtime/RealtimeThread.html#waitForNextPeriod"><code>waitForNextPeriod</code></a> and <a href="javax/realtime/RealtimeThread.html#waitForNextPeriodInterruptible"><code>waitForNextPeriodInterruptible</code></a> methods, and monitors cost overrun and deadline miss conditions based on its release parameters. For asynchronous event handlers, the scheduler monitors cost overruns and deadline misses.</p>
                <p>Release parameters also govern the treatment of the minimum interarrival time for sporadic schedulable objects.</p>
                <p>An instance of the <a href="javax/realtime/ProcessingGroupParameters.html"><code>ProcessingGroupParameters</code></a> class contains values that define a temporal scope for a processing group. If a schedulable object has an associated instance of the <code>ProcessingGroupParameters</code> class, it is said to execute within the temporal scope defined by that instance. A single instance of the <code>ProcessingGroupParameters</code> class can be (and typically is) associated with many SO's. If the implementation supports cost monitoring, the combined processor demand of all of the SO's associated with an instance of the <code>ProcessingGroupParameters</code> class must not exceed the values in that instance (i.e., the defined temporal scope). The processor demand is determined by the <tt>Scheduler</tt>.</p>
                <h2>Semantics and Requirements</h2>
                <p>This section establishes the semantics and requirements that are applicable across the classes of this chapter, and also defines the required scheduling algorithm. Semantics that apply to particular classes, constructors, methods, and fields will be found in the class description and the constructor, method, and field detail sections.</p>
                <h3>Semantics and Requirements Governing all Schedulers</h3>
                <ol>
                        <li>Schedulers other than the base scheduler may change the execution eligibility of the schedulable objects which they manage according to their scheduling algorithm.
                        <li>If an implementation provides any public schedulers other than the base scheduler it shall provide documentation describing each scheduler's semantics in language and constructs appropriate to the provided scheduling algorithms. This documentation must include the list of classes that constitute schedulable objects for the scheduler unless that list is the same as the list of schedulable objects for the base scheduler.
                        <li>This specification does not require any particular feasibility algorithm be implemented in the <tt>Scheduler</tt> object. The default algorithm always returns success for sporadic and periodic schedulable objects, as it assumes adequate resources, but it always returns false for aperiodic schedulable objects since no pool of resources would render such a load feasible.<li>Implementations that provide a scheduler with a feasibility algorithm other than the default are required to document the behavior of that algorithm and any assumptions it makes.
                </ol>
                <h3>Semantics and Requirements<a name="Anchor-35882" id="Anchor-35882"></a> Governing the Base Scheduler</h3>
                <p>The semantics for the base scheduler assume a uni-processor execution environment. While implementations of the RTSJ are not precluded from supporting multi-processor execution environments, no explicit consideration for such environments has been given in this specification.</p>
                <p>The base scheduler supports the execution of all schedulable objects and Java threads, but it only controls the release of periodic real-time threads, and aperiodic asynchronous event handlers.</p>
                <h4>Priorities</h4>
                <p>The execution scheduling semantics described in this section are defined in terms of a conceptual model that contains a set of queues of schedulable objects that are eligible for execution. There is, conceptually, one queue for each priority. No implementation structures are necessarily implied by the use of this conceptual model. It is assumed that no time elapses during operations described using this model, and therefore no simultaneous operations are possible.</p>
                <ol>
                        <li>The base scheduler must support at least 28 distinct values (real-time priorities) that can be stored in an instance of <tt>PriorityParameters</tt> in addition to the values 1 through 10 required to support the priorities defined by <code>java.lang.Thread</code>. The real-time priority values must be greater than 10, and they must include all integers from the base scheduler's <code>getMinPriority()</code> value to its <code>getMaxPriority()</code> value inclusive. The 10 priorities defined for <code>java.lang.Thread</code> must effectively have lower execution eligibility than the real-time priorities, but beyond this, their behavior is as defined by the specification of <code>java.lang.Thread.</code>
                        <li>Higher priority values in an instance of <tt>PriorityParameters</tt> have a higher execution eligibility.
                        <li>Assignment of any of the real-time priority values to any schedulable object controlled by the base priority scheduler is legal. It is the responsibility of application logic to make rational priority assignments.
                        <li>If two schedulable objects have different active priorities, the schedulable object with the higher active priority will always execute in preference to the schedulable object with the lower value when both are eligible for execution.
                        <li>A schedulable object that is executing will continue to execute until it either blocks, or is preempted by a higher-priority schedulable object.<li>The base scheduler does not use the <code>importance</code> value in the <a href="javax/realtime/ImportanceParameters.html"><code>ImportanceParameters</code></a> subclass of <code>PriorityParameters</code>.
                        
                        <li>The dispatching mechanism must allow the preemption of the execution of schedulable objects and Java threads at a point not governed by the preempted object.
                        <li>For schedulable objects managed by the base scheduler the implementation must not change the execution eligibility for any reason other than
                                <ol type="a">
                                        <li>Implementation of a priority inversion avoidance algorithm or
                                        <li>As a result of a program's request to change the priority parameters associated with one or more schedulable objects; e.g., by changing a value in a scheduling parameter object that is used by one or more schedulable objects, or by using <code>setSchedulingParameters()</code> to give a schedulable object a different <code>SchedulingParameters</code> value.
                                </ol>
                        <li>Use of <code>Thread.setPriority()</code>, any of the methods defined for schedulable objects, or any of the methods defined for parameter objects must not affect the correctness of the priority inversion avoidance algorithms controlled by <a href="javax/realtime/PriorityCeilingEmulation.html"><code>PriorityCeilingEmulation</code></a> and <a href="javax/realtime/PriorityInheritance.html"><code>PriorityInheritance</code></a> - see the <a href="sync_overview-summary.html"><em>Synchronization</em></a> chapter.
                        <li>A schedulable object that is preempted by a higher priority schedulable object is placed in the queue for its active priority, at a position determined by the implementation. The implementation must document the algorithm used for such placement. It is recommended that a preempted schedulable object be placed at the front of the appropriate queue.
                        <li>A real-time thread that performs a <tt>yield()</tt> is placed at the tail of the queue for its active priority level.
                        
                        <li>A blocked schedulable object that becomes eligible for execution is added to the tail of the queue for that priority. This behavior also applies to the initial release of a schedulable object.<li>For a schedulable object whose active priority is changed as a result of explicitly setting its base priority (through <code>PriorityParameters setPriority()</code> method, <code>RealtimeThread</code>'s <code>setSchedulingParameters()</code> method, or <code>Thread</code>'s <code>setPriority()</code> method), this schedulable object is added to the tail of the queue for its new priority level. Queuing when priorities are adjusted by priority inversion avoidance algorithms is governed by semantics specified in the <a href="sync_overview-summary.html"><em>Synchronization</em></a> chapter.
                        
                        <li>If schedulable object <var>A</var> managed by the base scheduler creates a Java thread, <var>B</var>, then the initial base priority of <var>B</var> is the priority value returned by the <tt>getMaxPriority</tt> method of <var>B</var>'s <tt>java.lang.ThreadGroup</tt> object.
                        <li>For real-time threads managed by the base scheduler, priority limits set by <code>java.lang.ThreadGroup</code> objects are not enforced.
                        <li><code>PriorityScheduler.getNormPriority()</code> shall be set to:<br>
                                <code>((PriorityScheduler.getMaxPriority() - PriorityScheduler.getMinPriority())/3) + PriorityScheduler.getMinPriority()</code>
                </ol>
                <h4>Parameter Values</h4>
                <p>The scheduler uses the values contained in the different parameter objects associated with a schedulable object to control the behavior of the schedulable object. The scheduler determines what values are valid for the schedulable objects it manages, which defaults apply and how changes to parameter values are acted upon by the scheduler. Invalid parameter values result in exceptions, as documented in the relevant classes and methods.</p>
                <ol>
                        <li>The default values for the base scheduler are:
                                <ol type="a">
                                        <li>Scheduling parameters are copied from the creating SO if possible; if the creating SO does not have scheduling parameters the default is an instance of the default priority parameters value.
                                        <li>Release parameters default to an instance of the default aperiodic parameters (see <a href="javax/realtime/AperiodicParameters.html"><code>AperiodicParameters</code></a>).
                                        <li>Memory parameters default to null which signifies that memory allocation by the schedulable object is not constrained by the scheduler.
                                        <li>Processing group parameters default to null which signifies that the schedulable object is not a member of any processing group and is not subject to processing group based limits on processor utilization.
                                        <li>The default scheduling parameter values for parameter objects created by an SO controlled by the base scheduler are: (see <a href="javax/realtime/PriorityScheduler.html"><code>PriorityScheduler</code></a>)
                                                <table border="1">
                                                        <tr>
                                                                <th>
                                                                        <div align="center">
                                                                                <strong>Attribute</strong></div>
                                                                </th>
                                                                <th>
                                                                        <div align="center">
                                                                                <strong>Default Value</strong></div>
                                                                </th>
                                                        </tr>
                                                        <tr>
                                                                <td>
                                                                        <div align="center">
                                                                                <em>Priority parameters</em></div>
                                                                </td>
                                                                <td></td>
                                                        </tr>
                                                        <tr>
                                                                <td>priority</td>
                                                                <td>norm priority</td>
                                                        </tr>
                                                        <tr>
                                                                <td>
                                                                        <div align="center">
                                                                                <em>Importance parameters</em></div>
                                                                </td>
                                                                <td></td>
                                                        </tr>
                                                        <tr>
                                                                <td>importance</td>
                                                                <td>No default. A value must be supplied.</td>
                                                        </tr>
                                                </table>
                                        
                                </ol>
                        <li>All numeric or <a href="javax/realtime/RelativeTime.html"><code>RelativeTime</code></a> attributes in parameter values must be greater than or equal to zero.
                        <li>Values of period must be greater than zero.
                        <li>Deadline values in <code>ReleaseParameters</code> objects must be less than or equal to their period values (where applicable), but the deadline may be greater than the minimum interarrival time in a <code>SporadicParameters</code> object.
                        <li>Changes to scheduling, release, memory, and processing group parameters (by methods on the schedulable objects bound to the parameters or by altering the parameter objects themselves) have two effects:
                                <ol type="a">
                                        <li>They immediately affect the feasibility test of the scheduler.
                                        <li>They potentially modify the behavior of the scheduler with regard to those schedulable objects. When such changes in behavior take effect depends on the parameter in question, and the type of schedulable object, as described below.
                                </ol>
                        <li>Changes to scheduling, release, memory, and processing group parameters are acted upon by the base scheduler as follows:
                                <ol type="a">
                                        <li>Changes to scheduling parameters take effect immediately except as provided by priority inversion avoidance algorithms.
                                        <li>Changes to release parameters depend on the parameter being changed, the type of release parameter object and the type of schedulable object:
                                                <ol type="i">
                                                        <li>Changes to the deadline and the deadline miss handler take effect at each release event as follows: if the <em>i<sup>th</sup></em> release event occurred at a time <i>t<sub>i</sub></i>, then the <em>i<sup>th</sup></em> deadline is the time <i>t<sub>i</sub>+D<sub>i</sub></i>, where <i>D<sub>i</sub></i> is the value of the deadline stored in the schedulable object's release parameters object at the time <i>t<sub>i</sub></i>. If a deadline miss occurs then it is the deadline miss handler that was installed in the schedulable object's release parameters at time <i>t<sub>i</sub></i> that is released.
                                                        <li>Changes to cost and the cost overrun handler take effect immediately.
                                                        <li>Changes to the period and start time values in <code>PeriodicParameters</code> objects are described in <a href="#PeriodicReal-timeThreads">&quot;Periodic Release of Real-time Threads&quot;</a> below. (The base scheduler does not manage the release of periodic schedulable objects other than periodic real-time threads.)
                                                        <li>Changes to the additional values in <code>AperiodicParameters</code> objects and <code>SporadicParameters </code>are described, respectively, in <a href="#AperiodicScheduling">&quot;Aperiodic Release Control&quot;</a> and <a href="#SporadicScheduling">&quot;Sporadic Release Control&quot;</a>, below. (The base scheduler does not manage the release of aperiodic schedulable objects other than aperiodic asynchronous event handlers.)
                                                        <li>Changes to the type of release parameters object generally take effect after completion, except as documented in the following sections.
                                                </ol>
                                        <li>Changes to memory parameters take effect immediately.
                                        <li>Changes to processing group parameters take effect as described in &quot;<a href="#processingGroups">Processing Groups</a>&quot; below.
                                        <li>Changes to the scheduler responsible for a schedulable object take effect at completion.
                                </ol>
                </ol>   
                <h4><a name="costMonitoring">Cost Monitoring</a></h4>
                <p>Cost monitoring is an optional facility in the implementation of the RTSJ, but when supported it must conform to the requirements and definitions as presented in this section.</p>
                <ol>
                        <li>The cost of an SO is defined by the value returned by invoking the <code>getCost</code> method of the SO's release parameters object.
                        <li>When an SO is initially released it's current CPU consumption is zero and as the SO executes, the current CPU consumption increases. The current CPU consumption is set to zero in response to certain actions as described below.
                        <li>If at any time, due to either execution of the SO or a change in the SO's cost, the current CPU consumption becomes greater than, or equal to, the current cost of the SO, then a cost overrun is triggered. The implementation is required to document the granularity at which the current CPU consumption is updated.
                        <li>When a cost overrun is triggered, the cost overrun handler associated with the SO, if any, is released. If the most recent release of the SO is the<em> i<sup>th</sup></em> release, and the<em> i+1</em> release event has not yet occurred, then:
                                <ol type="a">
                                        <li>If the state of the SO is either executing or eligible-for-execution, then the SO is placed into the state blocked-by-cost-overrun. There may be a bounded delay between the time at which a cost overrun occurs and the time at which the SO becomes blocked-by-cost-overrun.<li>Otherwise, the SO must have been blocked for a reason other than blocked-by-cost-overrun. In this case, the state change to blocked-by-cost-overrun is left pending: if the blocking condition for the SO is removed, then its state changes to blocked-by-cost-overrun.  There may be a bounded delay between the time at which the blocking condition is removed and the time at which the SO becomes blocked-by-cost-overrun.</ol>
                                Otherwise, if the <em>i+1</em> release event has occurred, the current CPU consumption is set to zero, the SO remains in its current state and the cost monitoring system considers the most recent release to now be the<em> i+1</em> release.<li>When the <em>i<sup>th</sup></em> release event occurs for an SO, the action taken depends on the state of the SO:
                                <ol type="a">
                                        <li>If the SO is blocked-by-cost-overrun then the cost monitoring system considers the most recent release to be the <em>i<sup>th</sup></em> release, the current CPU consumption is set to zero and the SO is made eligible for execution;
                                        <li>Otherwise, if the SO is blocked for a reason other than blocked-by-cost-overrun then:
                                                <ol type="i">
                                                        <li>If there is a pending state change to blocked-by-cost-overrun then: the pending state change is removed, the cost monitoring system considers the most recent release to be the <em>i<sup>th</sup></em> release, the current CPU consumption is set to zero and the SO remains in its current blocked state;
                                                        <li>Otherwise, no cost monitoring action occurs.
                                                </ol>
                                        <li>Otherwise no cost monitoring action occurs.
                                </ol>
                        <li>When the <em>i<sup>th</sup></em> release of an SO completes, and the cost monitoring system considers the most recent release to be the <em>i<sup>th</sup></em> release, then the current CPU consumption is set to zero and the cost monitoring system considers the most recent release to be the <em>i+1</em> release. Otherwise, no cost monitoring action occurs.<li>Changes to the cost parameter take effect immediately:
                                <ol type="a">
                                        <li>If the new cost is less than or equal to the current CPU consumption, and the old cost was greater than the current CPU consumption, then a cost overrun is triggered.
                                        <li>If the new cost is greater than the current CPU consumption:
                                                <ol type="i">
                                                        <li>If the SO is blocked-by-cost-overrun, then the SO is made eligible for execution;
                                                        <li>Otherwise, if the SO is blocked for a reason other than blocked-by-cost-overrun, and there is a pending state change to blocked-by-cost-overrun, then the pending state change is removed;
                                                        <li>Otherwise, no cost monitoring action occurs.
                                                </ol>
                                        
                                </ol>
                        <li>The state of the cost monitoring system for an SO can be <i>reset</i> by the scheduler (see <a href="#Anchor-47857">5c</a> in the Periodic Release of Real-time Threads section, below). If the most recent release of the SO is considered to be the <em>m<sup>th</sup></em> release, and the most recent release event for the SO was the <em>n<sup>th</sup></em> release event (where <i>n</i> &gt; <i>m</i>), then a reset causes the cost monitoring system to consider the most recent release to be the <em>n<sup>th</sup></em> release, and to zero the current CPU consumption.
                
                        
                </ol>
                <h4><a name="PeriodicReal-timeThreads">Periodic Release of Real-time Threads</a></h4>
                <p>A schedulable object with release parameters of type <a href="javax/realtime/PeriodicParameters.html"><code>PeriodicParameters</code></a> is expected to be released periodically. For asynchronous event handlers this would occur if the associated asynchronous event fired periodically. For real-time threads periodic release behavior is achieved by executing in a loop and invoking the <tt>RealtimeThread.waitForNextPeriod</tt> method, or its interruptible equivalent <tt>RealtimeThread.waitForNextPeriodInterruptible</tt> within that loop. For simplicity, unless otherwise stated, the semantics in this section apply to both forms of that method.</p>
                <ol>
                        <li>A periodic real-time thread's release characteristics are determined by the following<a name="Anchor-49575" id="Anchor-49575"></a>:
                                <ol type="a">
                                        <li>The invocation of the real-time thread's <code>start</code> method.
                                        <li>The action of the <code>RealtimeThread</code> methods <code>waitForNextPeriod</code>, <code>waitForNextPeriodInterruptible</code>, <code>schedulePeriodic</code> and <code>deschedulePeriodic</code>;
                                        <li>The occurrence of deadline misses and whether or not a miss handler is installed; and
                                        <li>The passing of time that generates periodic release events
                                </ol>
                        
                        <li>The <i>initial release event</i> of a periodic real-time thread occurs in response to the invocation of the its <code>start</code> method, in accordance with the start time specified in its release parameters - see <a href="javax/realtime/PeriodicParameters.html#PeriodicParameters(javax.realtime.HighResolutionTime start, javax.realtime.RelativeTime period, javax.realtime.RelativeTime cost, javax.realtime.RelativeTime deadline, javax.realtime.AsyncEventHandler overrunHandler, javax.realtime.AsyncEventHandler missHandler)"><code>PeriodicParameters</code></a>.
                        <li>Changes to the start time in a real-time thread's <code>PeriodicParameters</code> object only have an effect on its initial release time. Consequently, if a <code>PeriodicParameters</code> object is bound to multiple real-time threads, a change in the start time may affect all, some or none, of those threads, depending on whether or not <code>start</code> has been invoked on them.
                        <li>Subsequent release events occur as each period falls due, except as described below in 5(e), at times determined as follows: if the <em>i<sup>th</sup></em> release event occurred at a time <i>t<sub>i</sub></i>, then the <em>i+1</em> release event occurs at the time <i>t<sub>i</sub>+T<sub>i</sub></i>, where <i>T<sub>i</sub></i> is the value of the period stored in the real-time thread's <code>PeriodicParameters</code> object at the time <i>t<sub>i</sub></i>.
                        <li>The implementation should behave effectively as if the following state variables were added to a real-time thread's state, and manipulated by the actions in (<a href="#Anchor-49575">1</a>) as described below:<br>
                                boolean <code>descheduled</code>, integer <code>pendingReleases</code>, integer <code>missCount</code>, and boolean <code>lastReturn</code>.
                                <ol type="a">
                                        <li>Initially: <code>descheduled</code> = false, <code>pendingReleases</code> = 0, <code>missCount</code> = 0, and <code>lastReturn</code> = true.
                                        <li>When the real-time thread's <code>deschedulePeriodic</code> method is invoked: set the value of <code>descheduled</code> to true.
                                        <li>When the real-time thread's <code>schedulePeriodic</code> method is invoked: set the value of <code>descheduled</code> to false; then if the thread is blocked-for-release-event, set the value of <code>pendingReleases</code> to zero, and tell the cost monitoring system<a name="Anchor-47857" id="Anchor-47857"></a> to <a name="reset_ref">reset</a> for this thread.
                                        <li>When <code>descheduled</code> is true, the real-time thread is said to be <i>descheduled</i>.
                                        <li>A real-time thread that has been descheduled and is blocked-for-release-event will not receive any further release events until after it has been rescheduled by a call to <code>schedulePeriodic</code>; this means that no deadline misses can occur until the thread has been rescheduled. The descheduling of a real-time thread has no effect on its initial release.
                                        <li>When each period is due:
                                                <ol type="i">
                                                        <li>If the state of the real-time thread is blocked-for-release-event (that is, it is waiting in <code>waitForNextPeriod</code>), then if the thread is descheduled then do nothing, else increment the value of <code>pendingReleases</code>, inform cost monitoring that the next release event has occurred, and notify the thread to make it eligible for execution;
                                                        <li>Otherwise, increment the value of <code>pendingReleases</code>, and inform cost monitoring that the next release event has occurred.
                                                </ol>
                                        <li>On each deadline miss:
                                                <ol type="i">
                                                        <li>If the real-time thread has a deadline miss handler: set the value of <code>descheduled</code> to true, atomically release the handler with its <code>fireCount</code> increased by the value of <code>missCount+1</code> and zero <code>missCount</code>;
                                                        <li>Otherwise add one to the <code>missCount</code> value.
                                                </ol>
                                        <li>When the <code>waitForNextPeriod</code> method is invoked by the current real-time thread there are two possible behaviors depending on the value of <code>missCount</code>:
                                                <ol type="i">
                                                        <li>If <code>missCount</code> is greater than zero: decrement the <code>missCount</code> value; then if the <code>lastReturn</code> value is false, completion occurs: apply any pending parameter changes, decrement <code>pendingReleases</code>, inform cost monitoring the real-time thread has completed and return false; otherwise set the <code>lastReturn</code> value to false and return false.
                                                        <li>Otherwise, apply any pending parameter changes, inform cost monitoring of completion, and then wait while <code>descheduled</code> is true, or <code>pendingReleases</code> is zero. Then set the <code>lastReturn</code> value to true, decrement <code>pendingReleases</code>, and return true.
                                                </ol>
                                        
                                </ol>
                        <li>An invocation of the <code>waitForNextPeriodInterruptible</code> method behaves as described above with the following additions:
                                <ol type="a">
                                        <li>If the invocation commences when an instance of <a href="javax/realtime/AsynchronouslyInterruptedException.html"><code>AsynchronouslyInterruptedException</code></a> (AIE) is pending on the real-time thread, then the invocation immediately completes abruptly by throwing that pending instance as an <code>InterruptedException</code>. If this occurs, the most recent release has not completed. If the pending instance is the <a href="javax/realtime/AsynchronouslyInterruptedException.html#getGeneric()">generic AIE instance</a> then the interrupt state of the real-time thread is cleared.
                                        <li>If an instance of AIE becomes pending on the real-time thread while it is blocked-for-release-event, and the real-time thread is descheduled, then the AIE remains pending until the real-time thread is no longer descheduled. Execution then continues as in (c).
                                        <li>If an instance of AIE becomes pending on the real-time thread while it is blocked-for-release-event, and it is not descheduled, then this acts as a release event:
                                                <ol type="i">
                                                        <li>The real-time thread is made eligible for execution.
                                                        <li>Upon execution the invocation completes abruptly by throwing the pending AIE instance as an <code>InterruptedException</code>. If the pending instance is the <a href="javax/realtime/AsynchronouslyInterruptedException.html#getGeneric()">generic AIE instance</a> then the interrupt state of the real-time thread is cleared.
                                                        <li>If the AIE becomes pending at a time <i>t<sub>int</sub></i> then:
                                                                <ul>
                                                                        <li>The deadline associated with this release is the time <i>t<sub>int</sub>+D<sub>int</sub></i>, where <i>D<sub>int</sub></i> is the value of the deadline stored in the real-time thread's release parameters object at the time <i>t<sub>int</sub></i>.
                                                                        <li>The next release time for the real-time thread will be <i>t<sub>int</sub>+T<sub>int</sub></i>, where <i>T<sub>int</sub></i> is the value of the period stored in the real-time thread's release parameters object at the time <i>t<sub>int</sub></i>.
                                                                </ul>
                                                        <li>Cost monitoring is informed of the release event
                                                </ol>
                                        
                                </ol>
                                When the thrown AIE instance is caught, the AIE becomes pending again (as per the usual semantics for AIE) until it is explicitly cleared.
                        <li>If an aperiodic real-time thread has its release parameters set to periodic parameters, then calls <code>waitForNextPeriod</code>, the change from non-periodic to periodic scheduling effectively takes place between the call to <code>waitForNextPeriod</code> and the first periodic release. The first periodic release is determined by the start time specified in the real-time thread's periodic parameters. If that start time is an absolute time in the future, then that is the first periodic release time; if it is an absolute time in the past then the time at which <code>waitForNextPeriod</code> was called is the first periodic release time and the release occurs immediately. If the start time is a relative time, then it is relative to the time at which <code>waitForNextPeriod</code> was called; if that time is in the past then the release occurs immediately.
                        <li>If a periodic real-time thread has its release parameters set to be other than an instance of <code>PeriodicParameters</code> then the change from periodic to non-periodic scheduling effectively takes place immediately, unless the thread is blocked-for-release-event, in which case the change takes place after the next release event. When this change occurs, the deadline for the real-time thread is that which was in effect for the most recent release.
                </ol>
                <h5>Pseudo-Code for Periodic Thread Actions</h5>
                <p>The semantics of the previous section can be more clearly understood by viewing them in pseudo-code form for each of the methods and actions involved. In the following no mechanism for blocking and unblocking a thread is prescribed. The use of the wait and notify terminology in places is purely an aid to expressing the desired semantics in familiar terms.</p>
                <pre><code>// These values are part of thread state.
boolean descheduled     = false;
int     pendingReleases = 0;
boolean lastReturn      = true;
int     missCount       = 0;

deschedulePeriodic(){
    descheduled = true;
}

schedulePeriodic(){
    descheduled = false;
    if (blocked-for-release-event) {
        pendingReleases = 0;
        costMonitoringReset();
    }
}

onNextPeriodDue(){
    if (blocked-for-release-event) {
        if (descheduled) {
            ; // do nothing
        }
        else {
            pendingReleases++;
            notifyCostMonitoringOfReleaseEvent();
            notify it;  // make eligible for execution
        }
    } 
    else {
        pendingReleases++;
        notifyCostMonitoringOfReleaseEvent();
    }
}

onDeadlineMiss(){
    if (there is a miss handler) {
        descheduled = true;
        release miss handler with fireCount increased by missCount+1
        missCount = 0;
    } 
    else {
        missCount++;
    }
}

waitForNextPeriod{
    assert(pendingReleases &gt;= 0);
    if (missCount &gt; 0 ) {  
        // Missed a deadline without a miss handler
        missCount--;
        if (lastReturn == false) {
            //  Changes &quot;on completion&quot; take place here
            performParameterChanges();
            pendingReleases--;
            notifyCostMonitoringOfCompletion();
        }
        lastReturn = false;
        return false;
    } 
    else { 
        //  Changes &quot;on completion&quot; take place here
        performParameterChanges();
        notifyCostMonitoringOfCompletion();
        wait while (descheduled || pendingReleases == 0); // blocked-for-release-event
        pendingReleases--;
        lastReturn = true;
        return true;
    }
}</code></pre>
                <h4><a name="AperiodicScheduling">Aperiodic Release Control</a></h4>
                <p>Aperiodic schedulable objects are released in response to events occurring, such as the starting of a real-time thread, or the firing of an associated asynchronous event for an asynchronous event handler. The occurrence of these events, each of which is a potential release event, is termed an <i>arrival</i>, and the time that they occur is termed the <i>arrival time</i>.</p>
                <p>The base scheduler behaves effectively as if it maintained a queue, called the arrival time queue, for each aperiodic schedulable object. This queue maintains information related to each release event from its &quot;arrival&quot; time until the associated release completes, or another release event occurs - whichever is later. If an arrival is accepted into the arrival time queue, then it is a release event and the time of the release event is the arrival time. The initial size of this queue is an attribute of the schedulable object's aperiodic parameters, and is set when the parameter object is associated with the SO. Over time the queue may become full and its behavior in this situation is determined by the queue overflow policy specified in the SO's aperiodic parameters. There are four overflow policies defined:</p>
                <table width="95%" border="1">
                        <tr>
                                <th>
                                        <div align="center">
                                                <strong>Policy</strong></div>
                                </th>
                                <th>
                                        <div align="center">
                                                <strong>Action on Overflow</strong></div>
                                </th>
                        </tr>
                        <tr>
                                <td>IGNORE</td>
                                <td>Silently ignore the arrival. The arrival is not accepted, no release event occurs, and, if the arrival was caused programmatically (such as by invoking <tt>fire</tt> on an asynchronous event), the caller is not informed that the arrival has been ignored.</td>
                        </tr>
                        <tr>
                                <td>EXCEPT</td>
                                <td>Throw an <code>ArrivalTimeQueueOverflowException</code>. The arrival is not accepted, and no release event occurs, but if the arrival was caused programmatically, the caller will have <code>ArrivalTimeQueueOverflowException</code> thrown.</td>
                        </tr>
                        <tr>
                                <td>REPLACE</td>
                                <td>The arrival is not accepted and no release event occurs. If the completion associated with the last release event in the queue has not yet occurred, and the deadline has not been missed, then the release event time for that release event is replaced with the arrival time of the new arrival. This will alter the deadline for that release event. If the completion associated with the last release event has occurred, or the deadline has already been missed, then the behavior of the REPLACE policy is equivalent to the IGNORE policy.</td>
                        </tr>
                        <tr>
                                <td>SAVE</td>
                                <td>Behave effectively as if the queue were expanded as necessary to accommodate the new arrival. The arrival is accepted and a release event occurs.</td>
                        </tr>
                </table>
                <p>Under the SAVE policy the queue can grow and shrink over time.</p>
                <p>Changes to the queue overflow policy take effect immediately. When an arrival occurs and the queue is full, the policy applied is the policy as defined at that time.</p>
                <h5>Aperiodic Real-time Threads</h5>
                <p>Aperiodic real-time threads executing under the base scheduler have the following characteristics:</p>
                <ol>
                        <li>The initial release event occurs when <code>start</code> is invoked upon it.
                        <li>There are no subsequent release events.
                        <li>Completion occurs only through termination.
                        <li>When a deadline miss occurs, the deadline miss handler, if any, is released.
                        <li>If a cost overrun occurs the overrun handler, if any, is released and the real-time thread is placed in the state blocked-by-cost-overrun. It can become eligible for execution again only through a change to its cost parameter.
                </ol>
                <h4><a name="SporadicScheduling">Sporadic Release Control</a></h4>
                <p>Sporadic parameters include a minimum interarrival time, MIT, that characterizes the expected frequency of releases. When an arrival is accepted  implementation behaves as if it calculates the earliest time at which the next arrival could be accepted, by adding the current MIT to the arrival time of this accepted arrival. The scheduler guarantees that each sporadic schedulable object it manages, is released at most once in any MIT. It implements two mechanisms for enforcing this rule:</p>
                <ul>
                        <li><i>Arrival-time regulation</i> controls the work-load by considering the time between arrivals. If a new arrival occurs earlier than the expected next arrival time then a MIT violation has occurred, and the scheduler acts to prevent a release from occurring that would break the &quot;one release per MIT&quot; guarantee. Three arrival-time MIT-violation policies are supported:<br>
                                <table width="95%" border="1">
                                        <tr>
                                                <th>
                                                        <div align="center">
                                                                <strong>Policy</strong></div>
                                                </th>
                                                <th>
                                                        <div align="center">
                                                                <strong>Action on Violation</strong></div>
                                                </th>
                                        </tr>
                                        <tr>
                                                <td>IGNORE</td>
                                                <td>Silently ignore the violating arrival. The arrival is not accepted, no release event occurs, and, if the arrival was caused programmatically (such as by invoking <tt>fire</tt> on an asynchronous event), the caller is not informed that the arrival has been ignored.</td>
                                        </tr>
                                        <tr>
                                                <td>EXCEPT</td>
                                                <td>Throw a <code>MITViolationException</code>. The arrival is not accepted, and no release event occurs, but if the arrival was caused programmatically, the caller will have <code>MITViolationException</code> thrown.</td>
                                        </tr>
                                        <tr>
                                                <td>REPLACE</td>
                                                <td>The arrival is not accepted and no release event occurs. If the completion associated with the last release event in the queue has not yet occurred, and the deadline has not been missed, then the release event time for that release event is replaced with the arrival time of the new arrival. This will alter the deadline for that release event. If the completion associated with the last release event has occurred, or the deadline has already been missed, then the behavior of the REPLACE policy is equivalent to the IGNORE policy.</td>
                                        </tr>
                                </table>
                                <br>
                        <li><em>Execution-time regulation</em> occurs if the MIT violation policy SAVE is in effect. Under this policy all arrivals are accepted, but the scheduler behaves effectively as if released schedulable objects were further constrained by a scheduling policy that restricts execution to at most one release per MIT. This policy is only able to delay the effective release of a schedulable object. The deadline of each release event is always set relative to its arrival time. This policy may not schedule the effective release of an async event handler until after its deadline has passed. In this case the deadline miss handler is released at the deadline time even though the related async event has not yet reached its effective release.<br>
                                <br>
                                The SAVE policy makes no direct use of the next expected arrival time, but it maintains the value in case the MIT violation policy is changed from SAVE to one of the arrival-time regulation policies.
                </ul>
                <p>The <i>effective release time</i> of a release event <i>i</i> is the earliest time that the handler can be released in response to that release event. It is determined for each release event based on the MIT policy in force at the release event time:</p>
                <ul>
                        <li>For IGNORE, EXCEPT and REPLACE the effective release time is the release event time.
                        <li>For SAVE the effective release time of release event <i>i</i> is the effective release time of release event <i>i-1</i> plus the current value of the MIT.
                </ul>
                <p>The scheduler will delay the release associated with the release event at the head of the arrival time queue until the current time is greater than or equal to the effective release time of that release event.</p>
                <p>Changes to minimum interarrival time and the MIT violation policy take effect immediately, but only affect the next expected arrival time, and effective release time, for release events that occur after the change.</p>
                <h4>Aperiodic and Sporadic Release Control for Asynchronous Event Handlers</h4>
                <p>Asynchronous event handlers can be associated with one or more asynchronous events. When an asynchronous event is fired, all handlers associated with it are released, according to the semantics below:</p>
                <ol>
                        <li><a name="Anchor-Each-49575" id="Anchor-Each-49575"></a>Each firing of an associated asynchronous event is an arrival. If the handler has release parameters of type <code>AperiodicParameters</code>, then the arrival may become a release event for the handler, according to the semantics given in &quot;<a href="#AperiodicScheduling">Aperiodic Release Control</a>&quot; above. If the handler has release parameters of type <code>SporadicParameters</code>, then the arrival may become a release event for the handler, according to the semantics given in &quot;<a href="#SporadicScheduling">Sporadic Release Control</a>&quot; above. If the handler has release parameters of a type other than <code>SporadicParameters</code> then the arrival is a release event, and the arrival-time is the release event time.
                        <li>For each release event that occurs for a handler, an entry is made in the arrival-time queue and the handler's <code>fireCount</code> is incremented by one.
                        <li>Initially a handler is considered to be blocked-for-release-event and its <code>fireCount</code> is zero.
                        
                        <li>Releases of a handler are serialized by having its <code>handleAsyncEvent</code> method invoked repeatedly while its <code>fireCount</code> is greater than zero:
                                
                                <ol type="a">
                                        <li>Before invoking handleAsyncEvent, the <code>fireCount</code> is decremented and the front entry (if still present) removed from the arrival-time queue. 
                                        <li>Each invocation of <code>handleAsyncEvent</code>, in this way, is a release.
                                        
                                        <li>The return from <code>handleAsyncEvent</code> is the completion of a release.
                                        <li>Processing of any exceptions thrown by <code>handleAsyncEvent</code> occurs prior to completion.
                                
                                </ol>
                        
                        <li>The deadline for a release is relative to the release event time and determined at the release event time according to the value of the deadline contained in the handler's release parameters. This value does not change, except as described previously for handlers using a REPLACE policy for MIT violation or arrival-time queue overflow.
                        
                        <li>The application code can directly modify the <code>fireCount</code> as follows:
                                <ol type="a">
                                        <li>The <code>getAndDecrementPendingFireCount</code> method decreases the <code>fireCount</code> by one (if it was greater than zero), and returns the old value. This removes the front entry from the arrival-time queue but otherwise has no effect on the scheduling of the current schedulable object, nor the handler itself.<li>The <code>getAndClearPendingFireCount</code> method is functionally equivalent to invoking <code>getAndDecrementPendingFireCount</code> until it returns zero, and returning the original <code>fireCount</code> value.
                                        <li>The <code>getAndIncrementPendingFireCount</code> method attempts to increase the <code>fireCount</code> by one , and returns the old value. It behaves effectively as if a private event, associated only with this handler, were fired, in accordance with semantic <a href="#Anchor-Each-49575">(1)</a> above. This pseudo-firing is treated as a normal firing with respect to the other semantics in this section
                                        
                                        
                                        
                                        </ol>
                        <li>The scheduler may delay the invocation of <code>handleAsyncEvent</code> to ensure the effective release time honors any restrictions imposed by the MIT violation policy, if applicable, of that release event.
                        <li>Cost monitoring for an asynchronous event handler interacts with release events and completions as previously defined with the added requirement that at the completion of <code>handleAsyncEvent</code>, if the <code>fireCount</code> is now zero, then the cost monitoring system is told to reset for this handler.
                </ol>
                <h4><a name="processingGroups">Processing Groups<a name="Anchor-14210" id="Anchor-14210"></a></a></h4>
                <p>A processing group is defined by a processing group parameters object, and each SO that is bound to that parameter object is called a <i>member</i> of that processing group.</p>
                <p>Processing groups are only functional in a system that implements processing group enforcement. Although the processing group itself does not consume CPU time, it acts as a proxy for its members.</p>
                <h5>Definitions for Processing Groups</h5>
                <p>The <em>enforced priority</em> of a schedulable object is a priority with no execution eligibility. </p>
                <h5>Semantics for Processing Groups</h5>
                <ol>
                        <li>The deadline of a processing group is defined by the value returned by invoking the <code>getDeadline</code> method of the processing group parameters object.<li>A deadline miss for the processing group is triggered if any member of the processing group consumes CPU time at a time greater than the deadline for the most recent release of the processing group.<li>When a processing group misses a deadline:
                                <ol>
                                        <li type="a">If the processing group has a miss handler, it is released for execution
                                        <li type="a">If the processing group has no miss handler, no action is taken.</ol>
                        
                        <li>The cost of a processing group is defined by the value returned by invoking the <code>getCost</code> method of the processing group parameters object.
                        <li>When a processing group is initially released, its current CPU consumption is zero and as the members of the processing group execute, the current CPU consumption increases. The current CPU consumption is set to zero in response to certain actions as described below.<li>If at any time, due to either execution of the members of the processing group or a change in the parameter group's cost, the current CPU consumption becomes greater than, or equal to, the current cost of the processing group, then a cost overrun is triggered. The implementation is required to document the granularity at which the current CPU consumption is updated.
                        <li>When a cost overrun is triggered, the cost overrun handler associated with the processing group, if any, is released, and the processing group enters the <i>enforced state<a name="Anchor-35326" id="Anchor-35326"></a>.</i> For each member of the processing group:
                                <ol type="a">
                                        <li>The SO is placed into the enforced state.
                                        <li>When a SO is in the enforced state the base scheduler schedules that SO effectively as if the enforced priority were used in place of the SO's base priority.</ol>
                        <li>When the a release event occurs for a processing group, the action taken depends on the state of the processing group:
                                <ol type="a">
                                        <li>If the processing group is not in the enforced state then the current CPU consumption for the group is set to zero;
                                        <li>Otherwise the processing group is in the enforced state. It is removed from the enforced state, the current CPU consumption of the group is set to zero, and each member of the  group is removed from the enforced state.</ol>
                        <li>Changes to the cost parameter take effect immediately:
                                <ol type="a">
                                        <li>If the new cost is less than or equal to the current CPU consumption, and the old cost was greater than the current CPU consumption, then a cost overrun is triggered.
                                        <li>If the new cost is greater than the current CPU consumption:
                                                <ol type="i">
                                                        <li>If the processing group is enforced, then the processing group behaves as defined in semantic 8.
                                                        <li>Otherwise, no cost monitoring action occurs.
                                                </ol>
                                        
                                </ol>
                        <li>Changes to other parameters take place as follows:
                                
                                <ol>
                                        <li type="a">Start: can only be changed before the parameters group is started; i.e., before the start time or before the parameter object is associated with any SO. Changes take effect immediately.
                                        
                                        <li type="a">Period: at each release the next period is set based on the current value of the processing group's period.
                                        
                                        <li type="a">Deadline: at each release the next deadline is set based on the current value of the processing group's deadline.
                                        <li type="a">OverrunHandler: at each release the overrunHandler is set based on the current value of the processing group's overrunHandler.
                                        <li type="a">MissHandler: at each release the missHandler is set based on the current value of the processing group's missHandler.
                                </ol>
                        
                        <li type="1">Changes to the membership of the processing group take effect immediately. 
                        
                        
                        <li>The start time for the processing group may be relative or absolute.
                                
                                <ol>
                                        <li type="a">If the start time is absolute, the processing group behaves effectively as if the initial release time were the start time.
                                        
                                        <li type="a">If the start time is relative, the initial release time is computed relative to the time <code>start</code> or <code>fire</code> (as appropriate) is first called for a member of the processing group.
                                
                                </ol>
                </ol>
                <p>Note: Until a processing group starts, its budget cannot be replenished, but its members will be enforced if they exceed the initial budget. Also, once a processing group is started it behaves effectively as if it continued running continuously until the defining <code>ProcessingGroupParameters</code> object is freed.</p>
                <h2>Rationale</h2>
                <p>As specified the required semantics and requirements of this section establish a scheduling policy that is very similar to the scheduling policies found on the vast majority of real-time operating systems and kernels in commercial use today. The semantics and requirements for the base scheduler accommodate existing practice, which is a stated goal of the effort.  </p>
                <p>There is an important division between priority schedulers that force periodic context switching between tasks at the same priority, and those that do not cause these context switches.  By not specifying <cite> time slicing</cite> behavior this specification calls for the latter type of priority scheduler. In POSIX terms, SCHED_FIFO meets the RTSJ requirements for the base scheduler, but SCHED_RR does not meet those requirements.</p>
                <p>Although a system may not implement the first release (start) of a schedulable object as unblocking that schedulable object, under the base scheduler those semantics apply; i.e., the schedulable object is added to the tail of the queue for its active priority.</p>
                <p>Some research shows that, given a set of reasonable common assumptions, 32 distinct priority levels are a reasonable choice for close-to-optimal scheduling efficiency when using the rate-monotonic priority assignment algorithm (256 priority levels provide better efficiency). This specification requires at least 28 distinct priority levels as a compromise noting that implementations of this specification will exist on systems with logic executing outside of the Java Virtual Machine and may need priorities above, below, or both for system activities.</p>
                <p>In order not to undermine any feasibility analysis, the default behavior for implementations that support cost monitoring is that a schedulable object receives no more than <tt>cost</tt> units of CPU time during each release. The programmer must explicitly change the cost attribute to override the scheduler.</p>
                <p>Cost enforcement may be deferred while the overrun schedulable object holds locks that are out of application control, such as locks used to protect garbage collection. Applications should include the resulting jitter in any analysis that depends on cost enforcement.</p>
                <p>When a schedulable object is enforced because of cost overrun in a processing group the enforced priority is used for scheduling instead of the schedulable object's base priority.  The enforced priority's application is limited. The enforced priority is not returned as the schedulable object's priority from methods such as getPriority(), and the semantics of the active priority continue to operate when a schedulable object is enforced.</p>
<P>

<P>
<HR>

<HR>

</BODY>
</HTML>
