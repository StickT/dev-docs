<html>

	<meta http-equiv="content-type" content="text/html;charset=iso-8859-1">

	<body>
		<h1>Design</h1>The RTSJ comprises seven areas of extended semantics. This chapter introduces the extensions. Further detail, exact requirements, and rationale are given in the opening section of each relevant chapter. The seven areas are discussed in approximate order of their relevance to real-time programming. However, the semantics and mechanisms of each of the areas&#151;scheduling, memory management, synchronization, asynchronous event handling, asynchronous transfer of control, asynchronous thread termination, and physical memory access&#151;are all crucial to the acceptance of the RTSJ as a viable real-time development platform.<h2>Scheduling</h2>
		One of the concerns of real-time programming is to ensure the timely or predictable execution of sequences of machine instructions. Various scheduling schemes name these sequences of instructions differently. Typically used names include threads, tasks, modules, and blocks. The RTSJ introduces the concept of a <i>schedulable object. </i>These are the objects that the base scheduler manages, <code>RealtimeThread</code> and its subclasses and <code>AsyncEventHandler</code> and its subclasses.<br>
		<p><i>Timely execution of schedulable objects</i> means that the programmer can determine by analysis of the program, testing the program on particular implementations, or both whether particular threads will always complete execution before a given timeliness constraint. This is the essence of real-time programming: the addition of temporal constraints to the correctness conditions for computation. For example, for a program to compute the sum of two numbers it may no longer be acceptable to compute only the correct arithmetic answer but the answer must be computed before a particular time. Typically, temporal constraints are deadlines expressed in either relative or absolute time.</p>
		<p>We use the term <i>scheduling</i> (or <i>scheduling algorithm</i>) to refer to the production of a sequence (or ordering) for the execution of a set of schedulable objects (a <i>schedule</i>). This schedule attempts to optimize a particular metric (a metric that measures how well the system is meeting the temporal constraints). A <i>feasibility analysis</i> determines if a schedule has an acceptable value for the metric. For example, in hard real-time systems the typical metric is &quot;number of missed deadlines&quot; and the only acceptable value for that metric is zero. So-called soft real-time systems use other metrics (such as mean tardiness) and may accept various values for the metric in use.</p>
		<p>Many systems use thread priority in an attempt to determine a schedule. Priority is typically an integer associated with a schedulable object; these integers convey to the system the order in which the threads should execute. The generalization of the concept of priority is <i>execution eligibility</i>. We use the term <i>dispatching</i> to refer to that portion of the system which selects the thread with the highest execution eligibility from the pool of threads that are ready to run. In current real-time system practice, the assignment of priorities is typically under programmer control as opposed to under system control. The RTSJ's base scheduler also leaves the assignment of priorities under programmer control. However, the base scheduler also inherits methods from its superclass that may help determine feasibility.</p>
		<p>For the base scheduler the feasibility methods may assume a sufficiently fast processor to complete any proposed load on schedule. The RTSJ expects that the base scheduler may be subclassed in particular implementations (e.g., an EDF scheduler) and for those implementations the feasibility methods may correctly indicate the actual feasibility of the system under the given scheduler. Note that for the base scheduler the RTSJ is no different than most real-time operating systems in current use.</p>
		<p>The RTSJ requires a number of classes with names of the format <tt>&lt;string&gt;Parameters</tt> (such as <tt>SchedulingParameters)</tt>. An instance of one of these parameter classes holds a particular resource-demand characteristic for one or more schedulable objects. For example, the <tt>PriorityParameters </tt>subclass of <tt>SchedulingParameters</tt> contains the execution eligibility metric of the base scheduler, i.e., priority. At some time (construction-time or later when the parameters are replaced using setter methods), instances of parameter classes are bound to a schedulable object. The schedulable object then assumes the characteristics of the values in the parameter object. For example, if a <tt>PriorityParameters</tt> instance that had in its priority field the value representing the highest priority available is bound to a schedulable object, then that object will assume the characteristic that it will execute whenever it is ready in preference to all other schedulable objects (except, of course, those also with the highest priority).</p>
		<p>The RTSJ is written so as to allow implementers the flexibility to install arbitrary scheduling algorithms and feasibility analysis algorithms in an implementation of the specification. We do this because the RTJEG understands that the real-time systems industry has widely varying requirements with respect to scheduling. Use of the Java platform may help produce code written once but able to execute on many different computing platforms (known as Write Once, Run Anywhere.) The RTSJ both contributes to this goal and detracts from it.  The RTSJ's rigorous specification of the required priority scheduler is critical for portability of time-critical code, but the RTSJ permits and supports platform-specific schedulers which are not portable. </p>
		<h2>Memory Management</h2>
		Garbage-collected memory heaps have always been considered an obstacle to real-time programming due to the unpredictable latencies introduced by the garbage collector. The RTSJ addresses this issue by providing several extensions to the memory model, which support memory management in a manner that does not interfere with the ability of real-time code to provide deterministic behavior. This goal is accomplished by allowing the allocation of objects outside of the garbage-collected heap for both short-lived and long-lived objects.
		<h3>Memory Areas</h3>
		The RTSJ introduces the concept of a memory area. A memory area represents an area of memory that may be used for the allocation of objects. Some memory areas exist outside of the heap and place restrictions on what the system and garbage collector may do with objects allocated within. Objects in some memory areas are never garbage collected; however, the garbage collector must be capable of scanning these memory areas for references to any object within the heap to preserve the integrity of the heap.
		<p>There are four basic types of memory areas:</p>
		<ol>
			<li>Scoped memory provides a mechanism, more general than stack allocated objects, for managing objects that have a lifetime defined by scope.
			<li>Physical memory allows objects to be created within specific physical memory regions that have particular important characteristics, such as memory that has substantially faster access.
			<li>Immortal memory represents an area of memory containing objects that may be referenced without exception or garbage collection delay by any schedulable object, specifically including no-heap real-time threads and no-heap asynchronous event handlers.<li>Heap memory represents an area of memory that is the heap. The RTSJ does not change the determinant of lifetime of objects on the heap. The lifetime is still determined by visibility.
		</ol>
		<h3>Scoped Memory</h3>
		The RTSJ introduces the concept of scoped memory. A memory scope is used to give bounds to the lifetime of any objects allocated within it. When a scope is entered, every use of <tt>new</tt> causes the memory to be allocated from the active memory scope. A scope may be entered explicitly, or it can be attached to a schedulable object which will effectively enter the scope before it executes the object's <tt>run()</tt> method.
		<p>The contents of a scoped memory are discarded when no object in the scope can be referenced. This is done by a technique similar to reference counting the scope. A conformant implementation might maintain a count of the number of external references to each memory area. The reference count for a <tt>ScopedMemory</tt> area would be increased by entering a new scope through the <tt>enter()</tt> method of <tt>MemoryArea</tt>, by the creation of a schedulable object using the particular <tt>ScopedMemory</tt> area, or by the opening of an inner scope. The reference count for a <tt>ScopedMemory</tt> area would be decreased when returning from the <tt>enter()</tt> method, when the schedulable object using the <tt>ScopedMemory</tt> terminates, or when an inner scope returns from its <tt>enter()</tt> method. When the count drops to zero, the finalize method for each object in the memory would be executed to completion. Reuse of the scope is blocked  until finalization is complete.</p>
		<p>Scopes may be nested. When a nested scope is entered, all subsequent allocations are taken from the memory associated with the new scope. When the nested scope is exited, the previous scope is restored and subsequent allocations are again taken from that scope.</p>
		<p>Because of the lifetimes of scoped objects, it is necessary to limit the references to scoped objects, by means of a restricted set of assignment rules. A reference to a scoped object cannot be assigned to a variable from an outer scope, or to a field of an object in either the heap or the immortal area. A reference to a scoped object may only be assigned into the same scope or into an inner scope. The virtual machine must detect illegal assignment attempts and must throw an appropriate exception when they occur.</p>
		<p>The flexibility provided in choice of scoped memory types allows the application to use a memory area that has characteristics that are appropriate to a particular syntactically defined region of the code.</p>
		<h3>Immortal Memory</h3>
		<tt>ImmortalMemory</tt> is a memory resource shared among all schedulable objects and threads in an application. Objects allocated in <tt>ImmortalMemory</tt> are always available to non-heap threads and asynchronous event handlers without the possibility of a delay for garbage collection.<h3>Budgeted Allocation</h3>The RTSJ also provides limited support for providing memory allocation budgets for schedulable objects using memory areas. Maximum memory area consumption and maximum allocation rates for individual schedulable objects may be specified when they are created.<h2>Synchronization</h2>
		<h3>Terms</h3>
		For the purposes of this section, the use of the term <i>priority</i> should be interpreted somewhat more loosely than in conventional usage. In particular, the term <i>highest priority thread</i> merely indicates the most eligible thread&#151;the thread that the dispatcher would choose among all of the threads that are ready to run&#151;and doesn't necessarily presume a strict priority based dispatch mechanism.
		<h3>Wait Queues</h3>Threads and asynchronous event handlers waiting to acquire a resource must be released in execution eligibility order. This applies to the processor as well as to synchronized blocks. If schedulable objects with the same execution eligibility are possible under the active scheduling policy, such schedulable objects are awakened in FIFO order. For example:<ul>
			<li>Threads waiting to enter synchronized blocks are granted access to the synchronized block in execution eligibility order.
			<li>A blocked thread that becomes ready to run is given access to the processor in execution eligibility order.
			<li>A thread whose execution eligibility is explicitly set by itself or another thread is given access to the processor in execution eligibility order.
			<li>A thread that performs a yield will be given access to the processor after waiting threads of the same execution eligibility.
			<li>Threads that are preempted in favor of a thread with higher execution eligibility may be given access to the processor at any time as determined by a particular implementation. The implementation is required to provide documentation stating exactly the algorithm used for granting such access.
		</ul>
		<h3>Priority Inversion Avoidance</h3>
		Any conforming implementation must provide an implementation of the <tt>synchronized</tt> primitive with default behavior that ensures that there is no unbounded priority inversion. Furthermore, this must apply to code if it is run within the implementation as well as to real-time threads. The priority inheritance protocol must be implemented by default. The priority inheritance protocol is a well-known algorithm in the real-time scheduling literature and it has the following effect. If thread t<sub>1</sub> attempts to acquire a lock that is held by a lower-priority thread t<sub>2</sub>, then t<sub>2</sub>'s priority is raised to that of t<sub>1</sub> as long as t<sub>2</sub> holds the lock (and recursively if t<sub>2</sub> is itself waiting to acquire a lock held by an even lower-priority thread).
		
		<p>The specification also provides a mechanism by which the programmer can override the default system-wide policy, or control the policy to be used for a particular monitor, provided that policy is supported by the implementation. The monitor control policy specification is extensible so that new mechanisms can be added by future implementations.</p>
		<p>A second policy, priority ceiling emulation protocol (or highest locker protocol), is also specified for systems that support it. This protocol is also a well-known algorithm in the literature; somewhat simplified, its effect is as follows:</p>
		<ul>
			<li>A monitor is given a &quot;priority ceiling&quot; when it is created; the programmer should choose the highest priority of any thread that could attempt to enter the monitor.
			<li>As soon as a thread enters synchronized code, its (active) priority is raised to the monitor's ceiling priority. If, through programming error, a thread has a higher base priority than the ceiling of the monitor it is attempting to enter, then an exception is thrown.<li>On leaving the monitor, the thread has its active priority reset. In simple cases it will set be to the thread's previous active priority, but under some circumstances (e.g. a dynamic change to the thread's base priority while it was in the monitor) a different value is possible
		</ul>
		<p>Note that while the RTSJ requires that the execution of non-heap schedulable objects must not be delayed by garbage collection on behalf of lower-priority schedulable objects, an application can cause a no-heap schedulable object to wait for garbage collection by synchronizing using an object between an heap-using thread or schedulable object and a non-heap schedulable object. The RTSJ provides wait-free queue classes to provide protected, non-blocking, shared access to objects accessed by both regular Java threads and no-heap real-time threads. These classes are provided explicitly to enable communication between the real-time execution of non-heap schedulable objects and regular Java threads or heap-using schedulable objects.</p>
		<h3>Determinism</h3>
		
		Conforming implementations shall provide a fixed upper bound on the time required to enter a synchronized block for an unlocked monitor.
		<h2>Asynchronous Event Handling</h2>
		The asynchronous event facility comprises two classes: <tt>AsyncEvent</tt> and <tt>AsyncEventHandler</tt>. An <tt>AsyncEvent</tt> object represents something that can happen, like a POSIX signal, a hardware interrupt, or a computed event like an airplane entering a specified region. When one of these events occurs, which is indicated by the <code>fire()</code> method being called, the associated instances of <code>AsyncEventHandler</code> are scheduled and the <code>handleAsyncEvent()</code> methods are invoked, thus the required logic is performed. Also, methods on <code>AsyncEvent</code> are provided to manage the set of instances of <code>AsyncEventHandler</code> associated with the instance of <code>AsyncEvent</code>.
		<p>An instance of <tt>AsyncEventHandler</tt> can be thought of as something similar to a thread. It is a <tt>Runnable</tt> object: when the event fires, the associated handlers are scheduled and the <code>handleAsyncEvent()</code> methods are invoked. What distinguishes an <tt>AsyncEventHandler</tt> from a simple <tt>Runnable</tt> is that an <tt>AsyncEventHandler</tt> has associated instances of <tt>ReleaseParameters, SchedulingParameters</tt> and<tt> MemoryParameters</tt> that control the actual execution of the handler once the associated <tt>AsyncEvent</tt> is fired. When an event is fired, the handlers are executed asynchronously, scheduled according to the associated <tt>ReleaseParameters </tt>and<tt> SchedulingParameters</tt> objects, in a manner that looks like the handler has just been assigned to its own thread. It is intended that the system can cope well with situations where there are large numbers of instances of <tt>AsyncEvent</tt> and <tt>AsyncEventHandler</tt> (tens of thousands). The number of fired (in process) handlers is expected to be smaller.</p>
		<p>A specialized form of an <tt>AsyncEvent</tt> is the <tt>Timer</tt> class, which represents an event whose occurrence is driven by time. There are two forms of Timers: the <tt>OneShotTimer</tt> and the <tt>PeriodicTimer</tt>. Instances of <tt>OneShotTimer</tt> fire once, at the specified time. Periodic timers fire initially at the specified time, and then periodically according to a specified interval.</p>
		<p>Timers are driven by <tt>Clock</tt> objects. There is a special <tt>Clock</tt> object, <tt>Clock.getRealtimeClock()</tt>, that represents the real-time clock. The Clock class may be extended to represent other clocks the underlying system might make available (such as a execution time clock of some granularity).</p>
		<h2>Asynchronous Transfer of Control</h2>
		Many times a real-time programmer is faced with a situation where the computational cost of an algorithm is highly variable, the algorithm is iterative, and the algorithm produces successively refined results during each iteration. If the system, before commencing the computation, can determine only a time bound on how long to execute the computation (i.e., the cost of each iteration is highly variable and the minimum required latency to terminate the computation and receive the last consistent result is much less than about half of the mean iteration cost), then asynchronously transferring control from the computation to the result transmission code at the expiration of the known time bound is a convenient programming style. The RTSJ supports this and other styles of programming where such transfer is convenient with a feature termed Asynchronous Transfer of Control (ATC).
		<p>The RTSJ's approach to ATC is based on several guiding principles, informally outlined in the following lists.</p>
		<h3>Methodological Principles</h3>
		<ul>
			<li>A method must explicitly indicate its susceptibility to ATC. Since legacy code or library methods might have been written assuming no ATC, by default ATC must be turned off (more precisely, must be deferred as long as control is in such code).
			<li>Even if a method allows ATC, some code sections must be executed to completion and thus ATC is deferred in such sections. These ATC-deferred sections are synchronized methods, static initializers, and synchronized statements.<li>Code that responds to an ATC does not return to the point in the schedulable object where the ATC was triggered; that is, an ATC is an unconditional transfer of control. Resumptive semantics, which returns control from the handler to the point of interruption, are not needed since they can be achieved through other mechanisms (in particular, an <tt>AsyncEventHandler</tt>).
		</ul>
		<h3>Expressibility Principles</h3>
		<ul>
			<li>A mechanism is needed through which an ATC can be explicitly triggered in a target schedulable object. This triggering may be direct (from a source thread or schedulable object) or indirect (through an asynchronous event handler).<li>It must be possible to trigger an ATC based on any asynchronous event including an external happening or an explicit event firing from another thread or schedulable object. In particular, it must be possible to base an ATC on a timer going off.<li>Through ATC it must be possible to abort a  real-time thread but in a manner that does not carry the dangers of the <tt>Thread</tt> class's <tt>stop()</tt> and <tt>destroy()</tt> methods.
		</ul>
		<h3>Semantic Principles</h3>
		<ul>
			<li>If ATC is modeled by exception handling, there must be some way to ensure that an asynchronous exception is only caught by the intended handler and not, for example, by an all-purpose handler that happens to be on the propagation path.
			<li>Nested ATCs must work properly. For example, consider two, nested ATC-based timers and assume that the outer timer has a shorter time-out than the nested, inner timer. If the outer timer times out while control is in the nested code of the inner timer, then the nested code must be aborted (as soon as it is outside an ATC-deferred section), and control must then transfer to the appropriate <tt>catch</tt> clause for the outer timer. An implementation that either handles the outer time-out in the nested code, or that waits for the longer (nested) timer, is incorrect.</ul>
		<h3>Pragmatic Principles</h3>
		<ul>
			<li>There should be straightforward idioms for common cases such as timer handlers and real-time thread termination.<li>If code with a time-out completes before the timer's expiration, the timer needs to be automatically stopped and its resources returned to the system.
		</ul>
		<h2>Asynchronous Real-Time Thread Termination</h2>Although not a only real-time issue, many event-driven computer systems that tightly interact with external real-world non-computer systems (e.g., humans, machines, control processes, etc.) may require mode changes in their computational behavior as a result of significant changes in the non-computer real-world system. It would be convenient to program threads that abnormally terminate when the external real-time system changes in a way such that the thread is no longer useful. Without this facility, a thread or set of threads have to be coded in such a manner so that their computational behavior anticipated all of the possible transitions among possible states of the external system. It is an easier design task to code threads to computationally cooperate for only one (or a very few) possible states of the external system. When the external system makes a state transition, the changes in computation behavior might then be managed by an oracle, that terminates a set of threads useful for the old state of the external system, and invokes a new set of threads appropriate for the new state of the external system. Since the possible state transitions of the external system are encoded in only the oracle and not in each thread, the overall system design is easier.<p>Earlier versions of the Java language supplied mechanisms for achieving these effects: in particular the methods <tt>stop()</tt> and <tt>destroy()</tt> in class <tt>Thread</tt>. However, since <tt>stop()</tt> could leave shared objects in an inconsistent state, <tt>stop()</tt> has been deprecated. The use of <tt>destroy()</tt> can lead to deadlock (if a thread is destroyed while it is holding a lock) and although it was not deprecated until version 1.5 of the Java specification, its usage has long been discouraged. A goal of the RTSJ was to meet the requirements of asynchronous thread termination without introducing the dangers of the <tt>stop()</tt> or <tt>destroy()</tt> methods.</p>
		<p>The RTSJ accommodates safe asynchronous real-time thread termination through a combination of the asynchronous event handling and the asynchronous transfer of control mechanisms. To create such a set of real-time threads consider the following steps:</p>
		<ul>
			<li>Make all of the application methods of the real-time thread interruptible<li>Create an oracle which monitors the external world by binding a number of asynchronous event handlers to happenings which occur at appropriate mode changes
			<li>Have the handlers call <code>interrupt()</code> on each of the real-time threads affected by the change<li>After the handlers call <code>interrupt()</code> have them create a new set of real-time threads appropriate to the current state of the external world</ul>
		The effect of the happening is then to cause each interruptible method to abort abnormally by transferring control to the appropriate catch clause. Ultimately the <code>run()</code> method of the real-time thread will complete normally.
		<p>This idiom provides a quick (if coded to be so) but orderly clean up and termination of the real-time thread. Note that the oracle can comprise as many or as few asynchronous event handlers as appropriate.</p>
		<h2>Physical Memory Access</h2>
		The RTSJ defines classes for programmers wishing to directly access physical memory from code written in the Java language. <code>RawMemoryAccess</code> defines methods that allow the programmer to construct an object that represents a range of physical addresses. Access to the physical memory is then accomplished through <code>get[type]()</code> and <code>set[type]()</code> methods of that object where the type represents a word size, i.e., byte, short, int, long, float, and double. No semantics other than the <code>set[type]()</code> and <code>get[type]()</code> methods are implied. The <code>VTPhysicalMemory, LTPhysicalMemory,</code> and <code>ImmortalPhysicalMemory</code> classes allow programmers to construct an object that represents a range of physical memory addresses. When this object is used as a <code>MemoryArea</code> other objects can be constructed in the physical memory using the new keyword as appropriate.<u> </u>
		<p>The <code>PhysicalMemoryManager</code> is available for use by the various physical memory accessor objects <code>(VTPhysicalMemory, LTPhysicalMemory, ImmortalPhysicalMemory, RawMemoryAccess,</code> and <code>RawMemoryFloatAccess)</code> to create objects of the correct type that are bound to areas of physical memory with the appropriate characteristics - or with appropriate accessor behavior. Examples of characteristics that might be specified are: DMA memory, accessors with byte swapping, etc.  OEMs may provide <code>PhysicalMemoryTypeFilter</code> classes that allow additional characteristics of memory devices to be specified.</p>
		<h3>Raw Memory Access</h3>
		An instance of <code>RawMemoryAccess</code> models a range of physical memory as a fixed sequence of bytes. A full complement of accessor methods allow the contents of the physical area to be accessed through offsets from the base, interpreted as byte, short, int, or long data values or as arrays of these types.
		<p>Whether the offset specifies the most-significant or least-significant byte of a multibyte value is affected by the <tt>BYTE_ORDER</tt> static variable in class <code>RealtimeSystem</code>, possibly amended by a byte swapping attribute associated with the underlying physical memory type.</p>
		<p>The <code>RawMemoryAccess</code> class allows a real-time program to implement device drivers, memory-mapped I/O, flash memory, battery-backed RAM, and similar low-level software.</p>
		<p>A raw memory area cannot contain references to Java objects. Such a capability would be unsafe (since it could be used to defeat Java's type checking) and error prone (since it is sensitive to the specific representational choices made by the Java compiler).</p>
		<h3>Physical Memory Areas</h3>
		In many cases, systems needing the predictable execution of the RTSJ will also need to access various kinds of memory at particular addresses for performance or other reasons. Consider a system in which very fast static RAM was programmatically available. A design that could optimize performance might wish to place various frequently used Java objects in the fast static RAM. The <code>VTPhysicalMemory, LTPhysicalMemory</code>, and <code>ImmortalPhysicalMemory</code> classes allow the programmer this flexibility. The programmer would construct a physical memory object on the memory addresses occupied by the fast RAM.
		<h2>Exceptions</h2>
		The RTSJ introduces several new exceptions, and some new treatment of exceptions surrounding asynchronous transfer of control and memory allocators.
	</body>

</html>